\section{Introduction}
% Heres all the knowledge you need to understand shit
% Following DT's SI paper, we start with top line introductions of the main areas of our paper

Neural networks (NNs) and other machine learning (ML) models are becoming an increasingly important part of modern research and scientific application as they show wider application to data intensive problems and make progress where prior computational methods have proved otherwise intractable.

One method of training ML models involves the construction of a loss functions, or equivalently reward functions, which frames the training process as a high-dimensionality optimisation problem. In this setting the various parameters of the model are varied such as to minimise the aggregate loss of the models action over a large collection of inputs, compared to outputs. It is thus the loss function that grounds the model in a given problem. Their construction varies but they exhibit some general characteristics as will be discussed.

% TODO: merge these two paragraphs
% Question: What is a variational vs Sympletic Integration
% See DT1 for good complementary references and explantion here
The \SI{} (SI)\cite{tsangSLIMPLECTICINTEGRATORSVARIATIONAL2015} is a non-conservative extension of the the \SymI{}, a conservative variational integrator, which enables numerical integration of non-conservative systems that exhibits well defined bounds on the error in the energy and other conserved quantities of the system. These are based on the non-conservative action approach developed by Galley\cite{galleyClassicalMechanicsNonconservative2013} and Galley et al.\cite{galleyPrincipleStationaryNonconservative2014}.

\SymI{} are numerical integrators for Hamiltonian systems which have the property of preserving the canonical symplectic 2-form of the system. % Cite: https://en.wikipedia.org/wiki/Symplectic_integrator and DT's unpublished paper.
This makes them widely applicable to physical fields such as orbital dynamics and  molecular dynamics, among others \todo{Cite papers, some from DT2, some of my own} as they will by this nature,  preserve, or near preserve, the constants of motion of a system over a large number of integration steps.


% TODO: This feels a little stilted still. Why cant SymPy use automatic differentiation?
Currently the \SI{} is primarily implemented using computer algebra systems such as SymPy\cite{sympy} which allow for the computation of derivatives and integrals of mathematical expressions. These are general systems and are effective at working with mathematical expressions but pose limitations when seeking to increase computational speed or scale up to larger systems. Automatic-differentiation techniques are a collection of computational methods for the determination of the differential of large classes of \enquote{regular} scientific code in an efficient and accurate manner.

% Aside: I want to keep consistent terminology here. I quite like physics based neural networks
In this paper we focus on taking the existing mathematical framework of the \SI{} and adapting it to use more advanced computational methods and making it amenable to \autodiff{} to enable a wide class of new applications. These range from scalability to larger systems, for example in molecular dynamics, to its use as the foundation of a number of physics based loss functions which we will compare for empirical and theoretical suitability, with the goal that these could be used in the creation of machine learning models which encode physical knowledge and insight.

%\begin{enumerate}
%	\item X What is a slimpletic integrator
%	\item X What are they useful for
%	\item What is the need to auto-diff and a higher speed one
%	\item What \PHYSICS does this let us do?
%	\item How do we get to autodiff
%	\item Introduce the physical system which will be the through line of our model.
%\end{enumerate}

\section{Preliminaries}

\subsection{Lagrangian Mechanics}
\label{sec:lag-mech}

Lagrangian mechanics is a formalism of classical mechanics which places emphasis on the energies and systems of the system and that allows a flexibility in the exact variables used to parameterise the system. As it is traditionally phrased it works to solve the problem of determining the evolution of a physical system, parameterised by some generalised degrees of freedom $\set{q_1, \dots, q_n} \in \R$, across the timespan $[t_i, t_f] \subset \R$ from some initially known configuration. These generalised degrees of freedom are represented as the vector, $\vb q = \set{q_1, \dots, q_n} \in \R^n$, and this initial configuration $\vb q_0$.

This determination is done by constructing a functional,

\begin{equation}
  \label{eq:trad-action}
  S[\vb{q}] = \int_{t_i}^{t_f} L(\vb{q}, \dot{\vb{q}}, t) \rdd t
\end{equation}

where $S$ is known as the action of the system, $\dot\vbq$ is the standard time derivative of the systems path, and $L$ the Lagrangian, being traditionally made up of two components $T$, the kinetic energy of the system in some configuration at some time, and $V$, the potential energy of the system. These are combined as,

\begin{equation}
  \label{eq:trad-lag}
  L(\vb{q}, \dot{\vb{q}}, t) = T(\vb{q}, \dot{\vb{q}}, t) - V(\vb{q}, \dot{\vb{q}}, t).
\end{equation}

A physical solution is arrived on by then employing Hamilton's principle of least Action \cite{goldsteinClassicalMechanics2000} which provides that the physical path, $\vb q(t)$, is the one that \textit{extremises} the functional $S[\vb q]$ as defined in Equation \eqref{eq:trad-action}, ie one where the variation $\delta S$ with respect to any variation of the path $\delta \vbq(t)$ is zero. This equation can be found by solving the Euler-Lagrange equations,

\begin{equation}
	\label{eq:euler-lagrange}
	\frac{\p L}{\p q_i} - \frac{\dd}{\dd t}\frac{\p L}{\p \dot q_i} = 0
\end{equation}

for each generalised degree of $q_i$. To each we can also associate an conjugate momentum $p_i$ and generalised force $F_i$,

\begin{align}
  p_i = \frac{\p L }{\p \dot q_i} \\
  F_i = \frac{\p L}{\p q_i}
\end{align}

such that Equation \eqref{eq:euler-lagrange} reads in-line with Newton's second law, $F = \dot{p}_i$.

The focus on symmetries within the formalism comes to the fore however when we consider Noether's Theorem \cite{noetherInvariantVariationProblems1971} which states that every continuous symmetry of the action $S$ has a corresponding conserved quantity. A simple example of this can be seen for degrees of freedom which are said to be \emph{cyclic} in that the coordinate value itself, $q_i$, does not appear directly in the Lagrangian. It can be readily seen from Equation \eqref{eq:euler-lagrange} that if this is the case then,

\begin{equation}
  \frac{\dd}{\dd t}\frac{\p L}{\p \dot q_i} = 0
\end{equation}

which implies that the conjugate momentum $p_i$ is a conserved quantity of the system.

\subsection{Non-Conservative Actions}
\label{sec:intro-nc-actions}

Lagrangian mechanics as discussed applies only to conservative systems. While there exist other extensions to non-conservative systems, notably Rayleigh dissipation functions \cite{struttGeneralTheoremsRelating1871} for simple dissipative functions, we will focus on the method put forward by Galley et al. \cite{galleyClassicalMechanicsNonconservative2013}.

Within this method we incorporate non-conservative behaviour by formally double the degrees of freedom of the system discussed prior into two virtual paths $\vb q_{1,2}$ and considering a new non-conservative Lagrangian $\Lambda$ given by,

\begin{equation}
  \Lambda = L(\vbq_1, \dot\vbq_1, t) - L(\vbq_1, \dot\vbq_1, t) + K(\vbq_1, \vbq_2, \dot\vbq_1, \dot\vbq_2, t).
\end{equation}

This form can be consider as the contribution of the traditional conservative Lagrangian moving forwards along the path traced by $\vbq_1$, and then backwards (and hence negative) along that traced by $\vbq_2$. This additional term $K$ is labelled the non-conservative potential, representing a coupling between the two paths (if it could be broken down cleanly into a form of $V(\vbq_1) - V(\vbq_2)$ or similar then these could be absorbed into $L$ leaving $K = 0$). In practical considerations it is often useful (as will become clear shortly) to alter our choice of variables to instead be $\vbq_+ = {(\vbq_1 + \vbq_2)}/{2}$ and $\vbq_- = \vbq_1 - \vbq_2$. Within this formalism we can also define a corresponding conjugate momenta,

\begin{equation}
  \pi_{\mp, i} = \frac{\p \Lambda}{\p q_{\pm,i}}.
\end{equation}

To solve this system we follow in the same form as before, aiming to extemise a new action defined now in terms of $\Lambda$, however crucially we do so in what is known as the \enquote{physical limit} (P.L), where $\vbq_1 = \vbq_2$ or equivalently $\vbq_- \to \vb 0$. This gives the non-conservative Euler Lagrange equation,

\begin{equation}
	\label{eq:nc-el}
  	\left[\frac{\p \Lambda}{\p q_i} - \frac{\dd}{\dd t}\frac{\p \Lambda}{\p \dot q_i}\right]_{\text{P.L}} = 0
\end{equation}

note that only the Euler-Lagrange equation differentiating with respect to $\vbq_-$ survives (or equivalently for $\boldsymbol{\pi}_+$). A more complete explanation of this process, along with a derivation can be found in \cite{galleyClassicalMechanicsNonconservative2013}.

A corresponding form of Noetherâ€™s theorem can be shown to hold for these non-conservative systems where the Noether currents evolve in time due to the effect of the non-conservative coupling potential $K$ \cite{galleyPrincipleStationaryNonconservative2014}.

\subsection{The \SI}
\label{sec:intro-si}

% Setup system
% TOOD: Rephrase this to be variational integrators in general

To understand the \SI{} method we first consider the application of the \SymI{} to a traditional conservative system\footnote{This explanation takes its path from an unpublished paper by Tsang et al\cite{tsangVariationalSymplecticIntegrators}}. As before consider a system with $N$ degrees of freedom represented by some $\vbq \in \R^N$. We take that this system is governed by some Lagrangian, $L(\vbq, \dot{\vbq}, t) \in \R$.

With this setup we now choose to apply two successive procedures to our extremal path $\vb q(t)$, piecewise breakdown and discretisation with an aim to determine it numerically.

To start we break the trajectory down piecewise into a collection of $M$ sub-paths $\gamma_{n \in [M - 1]}$ where $[A] = \set{0, \dots, A}$, each defined on some portion of the whole timespan $[t_n, t_{n + 1}] \subset [t_i, t_f] \subset \R$ such that they cover it completely with overlaps only at the boundaries of the intervals. These together are such that the there is the correspondence,

\begin{equation}
\label{eq:pw-traj}
	\vb q(t) = \begin{cases}
		\gamma_n(t) &\text{for~} t \in [t_n, t_{n + 1}]
	\end{cases}
\end{equation}

for all $t \in [t_i, t_f]$. These paths define a collection of points $\vb q_{n \in [M]}$ which are their mutual values at the piecewise break points and the initial and final values for $n = 0$ and $n = M$ respectively.

As each piecewise curve constitutes in and of itself a physically attained trajectory we can state that any path $\vb{q}(t)$ which extremises the action for the whole timespan, must also extremise each piecewise portion, and visa-versa. 

This does not bring us closer to a numerical solution directly but allows us to freely split our integral domain as needed without loss of accuracy, and thus limit the error of our numerical-integration method which will necessarily increase with the number of time-steps or their size.

We now turn to the discretisation method itself. This is done using the Galerkin-Gauss-Lobatto (GGL) quadrature method of order $r \in \N_0$\cite{tsangSLIMPLECTICINTEGRATORSVARIATIONAL2015, farrVariationalIntegratorsGravitational2007} which approximates the integral from $t_n$ to $t_{n + 1}$ using the intermediary points

\begin{equation}
  t^{(i)}_n = t_n + (1 + x_i)\frac{\Delta t}{2}
\end{equation}

where $i \in [r + 1]$ and $x_i$ are the ordered roots of the the derivative of the $(r + 1)$th Legendre polynomial $P_{r + 1}$ and $\Delta t = t_f - t_i$. A choice for a given $r$ provides slimplectic maps that are accurate up an order $2r + 2$.

These allow us to approximate the path of the system within this quadrature using the associated cardinal functions for the GGL quadrature, labelled $\phi(t)$, as \(\vb q(t) = \phi(t) + \Or((\Delta t)^{r + 2})\) \todo{What does DT1 actually mean in this bit??? Bottom of pg2col1}. These provide a suitable approximation for the path derivative $\dot{\vb q}$ by the use the derivative matrix,

\begin{equation}
  D_{ij} = \begin{cases}
  	\dfrac{(r + 1)(r + 2)}{2\Delta t} &i = j = 0 \\\\
  	-\dfrac{(r + 1)(r + 2)}{2\Delta t} & i = j = r + 1 \\\\
  	0 & i = j \land i \notin \set{0, r + 1} \\\\
  	\dfrac{2P_{r + 1}(x_i)}{P_{r+1}(x_j)(x - x_j)\Delta t} & i\neq j
  \end{cases}
\end{equation}

which provides that,

\begin{equation}
  \dot\phi(t_n^{(i)}) = \sum_{j = 0}^{r + 1} D_{ij}q_n^{(j)}
\end{equation}

In turn this allows to express the integral as,

\begin{equation}
\label{eq:discr-action-1}
  \int_{t_n}^{t_{n + 1}} L(\vb q, \dot{\vb q}, t) \dd t \approx \sum_{i = 0}^{r + 1} w_i L(q_{n}^{(i)}, \dot\phi_{n}^{(i)}, t_{n}^{(i)})
\end{equation}

where the label the approximate expression $L_d^n$ and where $w_i$ are the quadrature weights given by

\begin{equation}
  w_i = \frac{\Delta t}{(r + 1)(r + 2)(P_{r + 1}(x_i))^2}
\end{equation}

Equation \eqref{eq:discr-action-1} strung together across the different piecewise sub-trajectories defined in Equation \eqref{eq:pw-traj} gives us the total discretised action of the system, shown in Equation \eqref{eq:discr-action-2}, that sets variational integrators \todo{is this sympl or variational} apart from their \todo{rant about other integrators at the start of this section} more general counterparts. 

\begin{equation}
\label{eq:discr-action-2}
  S_d = \sum_{n = 0}^{M} \sum_{i = 0}^{r + 1} w_i L(q_{n}^{(i)}, \dot\phi_{n}^{(i)}, t_{n}^{(i)})
\end{equation}

From here we then extremise this approximate path with respect to the mutual and interior \todo{have I used this terminology before?} points to obtain the equations of motion of the system as,

\begin{gather}
	\frac{\p L_d^{n-1}}{\p q_n} + \frac{\p L_d^{n}}{\p q_n} = 0 \\
	\label{eq:Ld-interior-eom} \frac{\p L_d^{n}}{\p q^{(i)}_n} = 0
\end{gather}

where $L_d^{n}$ is This first equation can be simplified further into two equivalent definitions for the discrete momentum \(\pi_n\),

\begin{align}
	\label{eq:pi-n} \pi_n &= -\frac{\p L_d^{n}}{\p q_n} \\
	\label{eq:pi-n+1} \pi_{n + 1} &= \frac{\p L_d^{n}}{\p q_{n + 1}}
\end{align}

and a continuity constraint at these mutual overlap points $\vb q_n$ in the same manner as we required for $\vb q_n$ itself. Together Equations \eqref{eq:Ld-interior-eom}, \eqref{eq:pi-n} can be solved to determine the values of $\vb q^{(i)}_n$, from which Equation \eqref{eq:pi-n+1} provides a form for determining $\pi_{n + 1}$.

This form is provided in terms of the traditional conservative Lagrangian $L$ however can be readily adapted to the non-conservative Lagrangian formalism discussed in \sref{sec:intro-nc-actions} by considering instead the non-conservative Euler-Lagrange Equation \eqref{eq:nc-el}, in effect substituting $L$ for the non-conservative Lagrangian $\Lambda$ and $\vb q_n$ for $\vb q_{n, -}$.

Continuing the consideration of Noether currents from prior sections, it can be shown that the continuous symmetries of the conservative action evolve as due to this now discretised $K_d$. It should be noted that GGL discretisation does not preserve time-shift symmetry, and hence energy is non conserved under the operation, however our \todo{As will be done} and previous results show that the fractional error is generally bounded over the integration.

\subsection{Physics Informed Neural Networks}
\label{sec:intro-pinn}

Physics informed neural networks (PINNs) are neural networks which include physical knowledge in their training processes \cite{raissiPhysicsInformedDeep2017}. Their most common application is to solving PDEs \cite{luDeepXDEDeepLearning2021,mengCompositeNeuralNetwork2020} where we take physically derived knowledge of the system as a prior in training and fit a neural network to solve some PDE incorporating the residuals into the models loss (loss functions will be discussed in more depth in \sref{sec:intro-lf}).

Neural networks more generally are a collection of linear and non-linear components composed together to form complex non-linear functions. At their base level the linear components can be expressed as the simple linear equation \(\vb{y} = W\vb{x} + \vb{b}\) where $W$ is a collection of weights for this component and $\vb{b}$ the biases; and the non-linear components are functions such as sigmoid or $\tanh$ which are included to stop collapse to linearity for the whole composition. These weights, biases, and other variables within the model constitute the model's \emph{parameters}.

This composition is useful in that it can be shown that, with sufficient complexity, these forms are dense in the space of Borel measurable functions and hence can take the place of almost any physical function or mathematical procedure \cite{hornikMultilayerFeedforwardNetworks1989}.

\subsection{Loss functions}
\label{sec:intro-lf}

Loss functions are the primary leaning method of neural networks and in PINNs act as the place where physics steps in to connect our computational model to reality. Loss functions work by attempting to minimise an arbitrary loss value computed from the parameters and a large dataset of known inputs and outputs for the model.

Loss functions in PINNs are often comprised of two components. First there is the prediction or physical loss which may for example be made up of the residuals of the model under PDE, boundary, and initial conditions of the system. Secondly there a regularisation loss term which helps to penalise overfitting to the training data, expressed as \enquote{complexity}, within the model. This might be implemented as an $\mathrm{L}^2$  of a vector containing all parameters of the model.

The exact algorithm for this optimisation varies and is the subject of much research \todo{If I say this I should probably cite it} however a common choice is Stochastic gradient descent. The requires that the loss function be differentiable (although methods exist for non-differentiable functions \cite{daubechiesIterativeThresholdingAlgorithm2003}). This property is provided by the automatic-differentiation techniques discussed in \sref{sec:intro-autodiff} but there are also other properties to consider\cite{sraOptimizationMachineLearning2012}. These include: higher-order differentiability, convexity, lipschitz continuity \cite{mohammadiPerformanceNoisyNesterov2019} among others. \todo{this needs a lot of work}

\subsection{Automatic-Differentiation, XLA, and Google's JAX}
\label{sec:intro-autodiff}

Automatic-differentiation is the process of computing the differential of \enquote{regular} code, ie. code that is substantially similar to code that one would normally write, with respect to one or more of its arguments. Google's JAX library \cite{jax2018github} contains one implementation of this in Python which works by passing \enquote{tracers} into the Python code which record the actions done to them such that a differential can be calculated.

JAX also incorporates the XLA (Accelerated Linear Algebra) library \cite{openxla-xla} where it uses similar tracing methods to translate a restricted, but large, subset of Python code into a series of low-level eifficent operations which can be executed at speed on the GPU or CPU.

These two technologies together show great promise in the fields of machine learning and simulation techniques as they allow for code that would previously have to be written in low-level languages such as C or C++ to be expressed in Python with significantly reduced overhead at runtime, and easier use by researchers.
